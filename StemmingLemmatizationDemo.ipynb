{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let us look at how we can do stemming using NLTK package\n",
    "https://www.nltk.org/howto/stem.html\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  :  cat\n",
      "catty  :  catti\n",
      "catlike  :  catlik\n",
      "kittens  :  kitten\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer() \n",
    "words = [\"cats\", \"catty\", \"catlike\",\"kittens\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", porter_stemmer.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer  :  comput\n",
      "compute  :  comput\n"
     ]
    }
   ],
   "source": [
    "words =[\"computer\",\"compute\"]\n",
    "for w in words: \n",
    "    print(w, \" : \", porter_stemmer.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programmer  :  programm\n",
      "programme  :  programm\n",
      "programs  :  program\n"
     ]
    }
   ],
   "source": [
    "words =[\"programmer\",\"programme\",\"programs\"]\n",
    "for w in words: \n",
    "    print(w, \" : \", porter_stemmer.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  :  cat\n",
      "catty  :  catti\n",
      "catlike  :  catlik\n",
      "kittens  :  kitten\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "words = [\"cats\", \"catty\", \"catlike\",\"kittens\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", snowball_stemmer.stem(w)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programmer  :  programm\n",
      "programme  :  programm\n",
      "programs  :  program\n"
     ]
    }
   ],
   "source": [
    "words =[\"programmer\",\"programme\",\"programs\"]\n",
    "for w in words: \n",
    "    print(w, \" : \", snowball_stemmer.stem(w)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let us now look at lemmatization using NLTK\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programmer  :  programmer\n",
      "programme  :  programme\n",
      "programs  :  program\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "words =[\"programmer\",\"programme\",\"programs\"]\n",
    "for w in words: \n",
    "    print(w, \" : \", wnl.lemmatize(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  :  cat\n",
      "catty  :  catty\n",
      "catlike  :  catlike\n",
      "kittens  :  kitten\n"
     ]
    }
   ],
   "source": [
    "words = [\"cats\", \"catty\", \"catlike\",\"kittens\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", wnl.lemmatize(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better  :  better\n",
      "best  :  best\n",
      "good  :  good\n"
     ]
    }
   ],
   "source": [
    "words = [\"better\", \"best\", \"good\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", wnl.lemmatize(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmers  :  programm : Programmers\n",
      "use  :  use : use\n",
      "programming  :  program : programming\n",
      "languages  :  languag : language\n",
      "to  :  to : to\n",
      "write  :  write : write\n",
      "computer  :  comput : computer\n",
      "programs  :  program : program\n"
     ]
    }
   ],
   "source": [
    "sentence =\"Programmers use programming languages to write computer programs\"\n",
    "words = word_tokenize(sentence) \n",
    "   \n",
    "for w in words: \n",
    "    print(w, \" : \",porter_stemmer.stem(w),\":\",wnl.lemmatize(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars  :  car : Cars\n",
      "is  :  is : is\n",
      "a  :  a : a\n",
      "good  :  good : good\n",
      "movie  :  movi : movie\n",
      "with  :  with : with\n",
      "many  :  mani : many\n",
      "animated  :  anim : animated\n",
      "car  :  car : car\n",
      "'s  :  's : 's\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Cars is a good movie with many animated car's\"\n",
    "words = word_tokenize(sentence) \n",
    "   \n",
    "for w in words: \n",
    "    print(w, \" : \", porter_stemmer.stem(w),\":\",wnl.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets  :  let : Lets\n",
      "meet  :  meet : meet\n",
      "today  :  today : today\n",
      ".  :  . : .\n",
      "In  :  In : In\n",
      "this  :  thi : this\n",
      "meeting  :  meet : meeting\n",
      "let  :  let : let\n",
      "us  :  us : u\n",
      "continue  :  continu : continue\n",
      "to  :  to : to\n",
      "discuss  :  discuss : discus\n",
      "on  :  on : on\n",
      "what  :  what : what\n",
      "we  :  we : we\n",
      "left  :  left : left\n",
      "during  :  dure : during\n",
      "the  :  the : the\n",
      "last  :  last : last\n",
      "time  :  time : time\n",
      "i  :  i : i\n",
      "met  :  met : met\n",
      "you  :  you : you\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Lets meet today. In this meeting let us continue to discuss on what we left during the last time i met you\"\n",
    "words = word_tokenize(sentence) \n",
    "   \n",
    "for w in words: \n",
    "    print(w, \" : \", porter_stemmer.stem(w),\":\",wnl.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let us do lemmatization with spaCy\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmers: programmer\n",
      "use: use\n",
      "programming: programming\n",
      "languages: language\n",
      "to: to\n",
      "write: write\n",
      "computer: computer\n",
      "programs: program\n"
     ]
    }
   ],
   "source": [
    "sentence =\"Programmers use programming languages to write computer programs\"\n",
    "doc = nlp(sentence)\n",
    "for word in doc:\n",
    "    print(word.text + ':', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats: cat\n",
      "catty: catty\n",
      "catlike: catlike\n",
      "kittens: kitten\n"
     ]
    }
   ],
   "source": [
    "sentence =\"cats catty catlike kittens\"\n",
    "doc = nlp(sentence)\n",
    "for word in doc:\n",
    "    print(word.text + ':', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars: car\n",
      "is: be\n",
      "a: a\n",
      "good: good\n",
      "movie: movie\n",
      "with: with\n",
      "many: many\n",
      "animated: animate\n",
      "car: car\n",
      "'s: 's\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Cars is a good movie with many animated car's\"\n",
    "doc = nlp(sentence)\n",
    "for word in doc:\n",
    "    print(word.text + ':', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets: let\n",
      "meet: meet\n",
      "today: today\n",
      ".: .\n",
      "In: in\n",
      "this: this\n",
      "meeting: meeting\n",
      "let: let\n",
      "us: -PRON-\n",
      "continue: continue\n",
      "to: to\n",
      "discuss: discuss\n",
      "on: on\n",
      "what: what\n",
      "we: -PRON-\n",
      "left: leave\n",
      "during: during\n",
      "the: the\n",
      "last: last\n",
      "time: time\n",
      "i: i\n",
      "met: meet\n",
      "you: -PRON-\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Lets meet today. In this meeting let us continue to discuss on what we left during the last time i met you\"\n",
    "doc = nlp(sentence)\n",
    "for word in doc:\n",
    "    print(word.text + ':', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
